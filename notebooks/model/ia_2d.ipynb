{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db97fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179858/2878516958.py:9: DeprecationWarning: scipy.misc is deprecated and will be removed in 2.0.0\n",
      "  from scipy import special, integrate, misc, interpolate\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import special, integrate, misc, interpolate\n",
    "\n",
    "import astropy.cosmology.units as cu\n",
    "import astropy.units as u\n",
    "from astropy.constants import M_sun\n",
    "u.add_enabled_units(cu);\n",
    "\n",
    "from astropy.cosmology import LambdaCDM\n",
    "H0 = 69.6\n",
    "cosmo = LambdaCDM(H0=H0, Om0=0.286, Ode0=0.714)\n",
    "h = H0/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14322924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyccl\n",
      "  Downloading pyccl-3.2.1.tar.gz (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/murray/.conda/envs/calum_conda/lib/python3.13/site-packages (from pyccl) (2.2.4)\n",
      "Building wheels for collected packages: pyccl\n",
      "  Building wheel for pyccl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyccl: filename=pyccl-3.2.1-py3-none-any.whl size=2544574 sha256=27743c09f613ef6b92b20f1da97faf0f5a66d25fec059f3d1920962bd363b17f\n",
      "  Stored in directory: /home/murray/.cache/pip/wheels/6a/c6/b3/8c615e580e91c465ac418bb0937c4a8b84e925fd2b8800781f\n",
      "Successfully built pyccl\n",
      "Installing collected packages: pyccl\n",
      "Successfully installed pyccl-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyccl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587f678",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyccl' has no attribute 'use_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyccl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mccl\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Ensure CLASS is used as the backend (this is the default if classy is installed)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mccl\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse_class\u001b[49m()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Your cosmology and power spectrum calculation remain the same\u001b[39;00m\n\u001b[32m      7\u001b[39m pk_nl = ccl.nonlin_matter_power(cosmo_ccl, k, a)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pyccl' has no attribute 'use_class'"
     ]
    }
   ],
   "source": [
    "import pyccl as ccl\n",
    "\n",
    "# Define cosmology for CCL\n",
    "cosmo_ccl = ccl.Cosmology(\n",
    "    Omega_c=cosmo.Om0 - (cosmo.Ob0 if cosmo.Ob0 is not None else 0),\n",
    "    Omega_b=cosmo.Ob0 if cosmo.Ob0 is not None else 0.049,  # default if not set\n",
    "    h=h,\n",
    "    sigma8=0.8,\n",
    "    n_s=0.96\n",
    ")\n",
    "\n",
    "# Define k and a arrays\n",
    "k = np.logspace(-3, 1, 100)  # h/Mpc\n",
    "a = 1.0  # today\n",
    "\n",
    "# Compute non-linear matter power spectrum\n",
    "pk_nl = ccl.nonlin_matter_power(cosmo_ccl, k, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('/global/homes/c/clamman/IA/')\n",
    "\n",
    "import pathlib\n",
    "parent_path = pathlib.Path.cwd().parent\n",
    "if 'IA' not in str(parent_path):   # for working in other directories. May need to rename \"IA\" to wherever spec-IA is located.\n",
    "    parent_path = parent_path / 'IA'\n",
    "    print('Parent path is not the IA directory. Assuming parent directory is IA')\n",
    "\n",
    "# reading in a file for the power spectrum\n",
    "ps_path = parent_path / 'spec-IA/example_data/AbacusSummit_base_c000_z0.800_power_nfft2048.csv' #ps_path = parent_path / 'spec-IA/example_data/AbacusSummit_base_c000_z0.800_power_nfft2048.csv'\n",
    "abacus_ps_nl = pd.read_csv(ps_path) # nonlinear matter power spectrum from AbacusSummit\n",
    "\n",
    "kz_spline_parent_paths = parent_path / 'spec-IA/example_data/kz_integral_splines/'\n",
    "kz_spline_paths = list(kz_spline_parent_paths.glob('*.npy')) # pre-computed values of the kz integral at given values of pimax, made with the above power spectum\n",
    "\n",
    "#####################################################################################################\n",
    "# GENRAL COSMOLOGY FUNCTIONS\n",
    "#####################################################################################################\n",
    "\n",
    "def g(z):\n",
    "    O_M = cosmo.Om(z)\n",
    "    O_DE = 1 - O_M\n",
    "    return (5/2) * O_M / (O_M**(4/7) - O_DE + (1 + 0.5*O_M) * (1 + (O_DE/70)))\n",
    "\n",
    "def D(z, norm_at_z0=False):\n",
    "    '''\n",
    "    Return growth factor at z. \n",
    "    If norm_at_z0 is False, this will be normalized so \\bar{D}(z) = (1+z)D(z) is 1 at matter-dominated era (z=infinity).\n",
    "    If norma_at_z1 is True, this will be normalized so D(z) is 1 at present epoch (z=0).\n",
    "    '''\n",
    "    if norm_at_z0:\n",
    "        return g(z) / ((1+z)*g(0))\n",
    "    else: \n",
    "        z_inf = 100000\n",
    "        return (g(z) / g(z_inf)) / (1+z)\n",
    "    \n",
    "def get_relative_bias(z, wp, D_base, wp_base):\n",
    "    '''get relative bias of a galaxy sample at z with projected correlation function wp, \n",
    "    compared to a sample with growth factor D_base and projected correlation function wp_base.'''\n",
    "    return (D_base / D(z)) * (wp/wp_base)**2\n",
    "       \n",
    "\n",
    "#####################################################################################################\n",
    "# FUNCTION TO CONVERT BETWEEN TAU AND A_IA\n",
    "#####################################################################################################\n",
    "def tau_to_AIA(tau, z, norm_at_z0=False):\n",
    "    '''\n",
    "    convert from our tau parameter to the commonly used IA amplitude parameter A_IA.\n",
    "    If norm_at_z0 is False, this will be normalized so \\bar{D}(z) = (1+z)D(z) is 1 at matter-dominated era (z=infinity).\n",
    "    If norma_at_z1 is True, this will be normalized so D(z) is 1 at present epoch (z=0).\n",
    "    '''\n",
    "    C1 = 5*10**(-14) * ((u.Mpc)**3 / h**2) / M_sun\n",
    "    rho_m0 = cosmo.Om(z) * cosmo.critical_density0\n",
    "    AIA = - (tau / C1) * (D(z, norm_at_z0=norm_at_z0) / rho_m0)\n",
    "    return AIA.to(u.Mpc/u.Mpc).value\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "# FUNCTION TO CALCULATE MODEL PREDICTION FOR GIVEN MEASUREMENT OF RELATIVE PROJECTED ELLIPTICITY\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "def precompute_kz_integral(pimax_values, PS_data, directory, PS_min = 1e-4, PS_max = 2e2, n_samples=100, warning_handling='once', pi_weighting=False, gauss_params=None, pimax_rp=None, overwrite=True):\n",
    "    '''\n",
    "    Precompute the integral of the kz integral and save a spline as a function of K (in log space)\n",
    "    This is used to speed up the calculation of rel_e_to_tau.\n",
    "    \n",
    "    INPUT:\n",
    "    ------------------\n",
    "    pimax_values: array of shape (n,). Line-of-sight distance \n",
    "    PS_data: dictonary or DataFrame of matter power spectrum values. Must contain columns 'k' and 'P'. Default is a non-linear matter power spectrum from AbacusSummit.\n",
    "    directory: string. Directory path to save the spline files.\n",
    "    PS_min, PS_max: floats. Range of k to use for the power spectrum [h/Mpc]\n",
    "    n_samples: int. Number of samples to use for the spline. For a better integration, this function will add a few more to better sample where sincx = 0\n",
    "    gauss_params: array of shape (2n,). Parameters for the gaussian fit. If pi_weighting = True, this is the parameters for the gaussian fit to the 2D correlation function.\n",
    "                  will use parameters as sigma1, width1, sigma2, width2, etc.\n",
    "    RETURNS:\n",
    "    ------------------\n",
    "    None. Saves the spline files in the directory.\n",
    "    '''\n",
    "    \n",
    "    if overwrite == False:\n",
    "        if pi_weighting == False:\n",
    "            if all([os.path.exists(directory+'/kz_integral_NL_spl_pimax_'+str(pmi)+'.npy') for pmi in pimax_values]):\n",
    "                print('All files exist. Skipping')\n",
    "                return None\n",
    "        else:\n",
    "            if os.path.exists(directory+'/kz_integral_NL_spl_Wpimaxrp_'+str(pimax_rp)+'.pkl'):\n",
    "                print('File exists. Skipping')\n",
    "                return None\n",
    "    \n",
    "    warnings.filterwarnings(warning_handling)\n",
    "    \n",
    "    # using interpolation to get P(k)\n",
    "    tck_PS = interpolate.splrep(np.log10(PS_data['k']), np.log10(PS_data['P']), s=4e-3)\n",
    "    \n",
    "    def get_PS(k):\n",
    "        return 10**(interpolate.splev(np.log10(k), tck_PS))\n",
    "\n",
    "    if pi_weighting == False:\n",
    "        def kz_integrand(kz, K, pimax):\n",
    "            '''does not include front constant of b_gal * pimax / pi'''\n",
    "            k_squared = kz**2 + K**2\n",
    "            sinc_value = scipy.special.sinc( (kz * pimax) / np.pi )  # THIS SCIPY SINC INCLUDES PI NORMALIZATION > MUST DIVIDE BY PI\n",
    "            return get_PS(np.sqrt(k_squared)) * (K**2 / k_squared) * sinc_value\n",
    "    else:\n",
    "        n_gaussians = int(len(gauss_params) / 2)\n",
    "        if n_gaussians == 1:\n",
    "            def kz_integrand(kz, K):\n",
    "                k_squared = kz**2 + K**2\n",
    "                gaussian_sum_fs = get_gauss_sum_fs_1D(kz, *gauss_params)\n",
    "                return get_PS(np.sqrt(k_squared)) * (K**2 / k_squared) * gaussian_sum_fs\n",
    "        elif n_gaussians == 3:\n",
    "            def kz_integrand(kz, K):\n",
    "                k_squared = kz**2 + K**2\n",
    "                gaussian_sum_fs = get_gauss_sum_fs_3D(kz, *gauss_params) \n",
    "                return get_PS(np.sqrt(k_squared)) * (K**2 / k_squared) * gaussian_sum_fs\n",
    "        else:\n",
    "            raise ValueError('Only 1 or 3 gaussians supported')\n",
    "\n",
    "    Ks_sample_values = np.logspace(np.log10(PS_min), np.log10(PS_max), n_samples)    \n",
    "    \n",
    "    if pi_weighting == False:# or pi_weighting == True:\n",
    "        # For better integration: adding more samples around where sincx = 0\n",
    "        n_pi_steps = 1000 # must be integer\n",
    "        max_pi = 1e3  # must be integer\n",
    "        min_pi = 1e1  # must be integer\n",
    "        Ks_extra_values = (np.arange(0, n_pi_steps) * np.pi * max_pi/(3*n_pi_steps)) + float(int(min_pi/np.pi))*np.pi\n",
    "        Ks_sample_values = np.sort(np.concatenate((Ks_sample_values, Ks_extra_values)))\n",
    "    \n",
    "    if pi_weighting == False:\n",
    "        for pmi in pimax_values:\n",
    "            kz_integral_values = []\n",
    "            for K in Ks_sample_values:\n",
    "                kz_integral_values.append(scipy.integrate.romberg(kz_integrand, a=PS_min, b=PS_max, args=[K, pmi], rtol=1.48e-8, divmax=15)) # integrate over kz\n",
    "            tck_kz_integral = interpolate.splrep(np.log10(Ks_sample_values), kz_integral_values, s=1e-3)\n",
    "            \n",
    "            # save the spline\n",
    "            print('saving for pimax =', pmi)\n",
    "            np.save(directory+'/kz_integral_NL_spl_pimax_'+str(pmi)+'.npy', tck_kz_integral)\n",
    "    \n",
    "    else:\n",
    "        kz_integral_values = []\n",
    "        for K in Ks_sample_values:\n",
    "            value = scipy.integrate.romberg(kz_integrand, a=PS_min, b=PS_max, args=[K], rtol=1.48e-8, divmax=15)\n",
    "            kz_integral_values.append(value) # integrate over kz\n",
    "        tck_kz_integral = interpolate.splrep(np.log10(Ks_sample_values), kz_integral_values, s=1e-3)\n",
    "        print('saving pimax-weighted values for rp =', pimax_rp)\n",
    "        with open(directory+'/kz_integral_NL_spl_Wpimaxrp_'+str(n_gaussians)+'D_'+str(pimax_rp)+'.pkl', 'wb') as f:\n",
    "            pickle.dump(tck_kz_integral, f)\n",
    "    print('Finished')\n",
    "    return None\n",
    "\n",
    "def precompute_kz_integral_1D_gauss_limber(pimax_values, PS_data, directory, gauss_std, PS_min = 1e-4, PS_max = 2e2, n_samples=100, warning_handling='once', pimax_rp=None, overwrite=True):\n",
    "    # assume that only the kz=0 contributions matter. Typically only true when r_p << r_par\n",
    "\n",
    "    '''\n",
    "    Precompute the integral of the kz integral and save a spline as a function of K (in log space)\n",
    "    \n",
    "    INPUT:\n",
    "    ------------------\n",
    "    pimax_values: array of shape (n,). Line-of-sight distance \n",
    "    PS_data: dictonary or DataFrame of matter power spectrum values. Must contain columns 'k' and 'P'. Default is a non-linear matter power spectrum from AbacusSummit.\n",
    "    directory: string. Directory path to save the spline files.\n",
    "    PS_min, PS_max: floats. Range of k to use for the power spectrum [h/Mpc]\n",
    "    n_samples: int. Number of samples to use for the spline. For a better integration, this function will add a few more to better sample where sincx = 0\n",
    "    gauss_params: array of shape (2n,). Parameters for the gaussian fit. If pi_weighting = True, this is the parameters for the gaussian fit to the 2D correlation function.\n",
    "                  will use parameters as sigma1, width1, sigma2, width2, etc.\n",
    "    RETURNS:\n",
    "    ------------------\n",
    "    None. Saves the spline files in the directory.\n",
    "    '''\n",
    "    \n",
    "    if overwrite == False:\n",
    "        if os.path.exists(directory+'/kz_integral_NL_spl_Wpimaxrp_1D_limber_'+str(pimax_rp)+'.pkl'):\n",
    "            print('File exists. Skipping')\n",
    "            return None\n",
    "        \n",
    "    Ks_sample_values = np.logspace(np.log10(PS_min), np.log10(PS_max), n_samples)    \n",
    "\n",
    "    kz_integral_values = gauss_std * get_PS(Ks_sample_values)\n",
    "    tck_kz_integral = interpolate.splrep(np.log10(Ks_sample_values), kz_integral_values, s=1e-3)\n",
    "    print('saving values for rp =', pimax_rp)\n",
    "    with open(directory+'/kz_integral_NL_spl_Wpimaxrp_1D_limber_'+str(pimax_rp)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(tck_kz_integral, f)\n",
    "    print('Finished')\n",
    "    return None\n",
    "    \n",
    "# CALCULATING FANCY J\n",
    "def get_fancyJ(Rmin, Rmax, bigK):\n",
    "    return (2*scipy.special.j0(Rmin*bigK) + Rmin*bigK*scipy.special.j1(Rmin*bigK) - 2*scipy.special.j0(Rmax*bigK) - Rmax*bigK*scipy.special.j1(Rmax*bigK)) * 2 / (bigK**2 * (Rmax**2 - Rmin**2))\n",
    "\n",
    "\n",
    "def compute_rel_e_model(rel_e_measurement, wp_measurement, pimax_values, b_gal, z = 0.8, rel_e_randoms=None,\n",
    "                 PS_min = 1e-4, PS_max = 2e2, PS_data = abacus_ps_nl, PS_z = 0.8, precomputed_kz_integral_paths = [str(kzs) for kzs in kz_spline_paths], warning_handling='once'):\n",
    "    '''\n",
    "    Compute a model prediction at each bin of projected separation. This code assumes a tau value of 1.\n",
    "    \n",
    "    INPUT - REQUIRED:\n",
    "    ------------------\n",
    "    rel_e_measurement: dictonary or DataFrame of projected relative ellipticity measurement between a shape catalog and a tracer catalog.\n",
    "        must contain columns 'R_bin_min', 'R_bin_max', ''.\n",
    "    wp: dictonary or DataFrame of projected cross-correlation function between a shape and a tracer catalog.\n",
    "        must contain columns 'R_bin_min', 'R_bin_max', 'wp'.\n",
    "    Rbins: array of shape (n+1,). Bin edges that rel_e_measurment and wp were made in [Mpc/h]\n",
    "    pimax_values: float or array of shape (n,). Line-of-sight distance that rel_e_measurement and wp were made [Mpc/h]\n",
    "    b_gal: float. bias of the galaxy catalog used for tracers\n",
    "    z: float. redshift of galaxies used in measurement\n",
    "    \n",
    "    INPUT - OPTIONAL:\n",
    "    ------------------\n",
    "    rel_e_randoms: dictonary or DataFrame of projected relative ellipticity measurement between a shape catalog and a random catalog.\n",
    "        must contain columns 'R_bin_min', 'R_bin_max', 'relAng_plot'.\n",
    "    PS_min, PS_max: floats. Range of k to use for the power spectrum [h/Mpc]\n",
    "    PS_data: dictonary or DataFrame of matter power spectrum values. Must contain columns 'k' and 'P'. Default is a non-linear matter power spectrum from AbacusSummit.\n",
    "    PS_z = float. redshift of the power spectrum. Default is 0.8.\n",
    "    precomputed_kz_integral_paths: list of paths to precomputed values of the kz integral afor given pi values, made with the above power spectum. \n",
    "        Must be formatted as the output of precompute_kz_integrand.\n",
    "    '''\n",
    "    warnings.filterwarnings(warning_handling)\n",
    "    \n",
    "    if rel_e_measurement['R_bin_min'][0] != wp_measurement['R_bin_min'][0]:\n",
    "        print('Warning - R bins do not match between rel_e_measurement and wp_measurement!! Continuing with the R bins from rel_e_measurement')\n",
    "        \n",
    "    # if the redshift of the measurement and power spectrum are different, adjust using growth factor\n",
    "    D_norm = 1\n",
    "    if z != PS_z:\n",
    "        D_norm = (D(z) / D(PS_z))**2\n",
    "\n",
    "        \n",
    "    # read in the pre-computed value of the kz integral (made with precompute_kz_integral)\n",
    "    splines = [np.load(path, allow_pickle=True) for path in precomputed_kz_integral_paths]\n",
    "    pimax_values = [round(float(path.split('_')[-1].split('.npy')[0]), 2) for path in precomputed_kz_integral_paths]\n",
    "\n",
    "    def get_kz_integral_spl(K, pimax, b_gal):\n",
    "        try:\n",
    "            i_to_use = list(pimax_values).index(round(pimax, 2))\n",
    "        except ValueError:\n",
    "            print('Pimax value not found in pre-computed values. Use precompute_kz_integral() to generate first. Continuing with a pimax value of 30.0 Mpc/h')\n",
    "            pimax = 30\n",
    "            i_to_use = list(pimax_values).index(round(pimax, 2))\n",
    "        front_constant = b_gal * pimax / np.pi\n",
    "        return front_constant * (interpolate.splev(np.log10(K), splines[i_to_use]))\n",
    "    \n",
    "    # for last ingetral\n",
    "    def K_integrand(K, Rmin, Rmax, pimax, b_gal, PS_min = 10**-4, PS_max = 100):\n",
    "        kz_integral = get_kz_integral_spl(K, pimax, b_gal)\n",
    "        return K * get_fancyJ(Rmin, Rmax, K) * kz_integral\n",
    "\n",
    "    def get_model_est(Rmin, Rmax, pimax, b_gal, tau=1, PS_min = 10**-4, PS_max = 100):\n",
    "        \n",
    "        bar_wp = get_bar_wp(Rmin, Rmax)\n",
    "        K_integral = scipy.integrate.romberg(K_integrand, a=PS_min, b=PS_max, args=[Rmin, Rmax, pimax, b_gal], rtol=1.48e-8, divmax=15) # integrate over K\n",
    "        \n",
    "        return tau * K_integral / (2*pimax + bar_wp)\n",
    "    \n",
    "    randoms = 0\n",
    "    if rel_e_randoms is not None:\n",
    "        if rel_e_randoms['R_bin_min'][0] != rel_e_measurement['R_bin_min'][0]:\n",
    "            print('Warning - R bins do not match between rel_e_measurement and rel_e_randoms!! Continuing with the R bins from rel_e_measurement')\n",
    "        randoms = rel_e_randoms['relAng_plot']\n",
    "        \n",
    "    R_bin_centers = (rel_e_measurement['R_bin_min']+rel_e_measurement['R_bin_max'])/2\n",
    "    R_bin_edges = np.append(np.asarray(rel_e_measurement['R_bin_min']), rel_e_measurement['R_bin_max'][-1])\n",
    "    #ia_measurement = rel_e_measurement['relAng_plot'] - randoms\n",
    "    wp_values = wp_measurement['wp']\n",
    "\n",
    "    def get_wp(R):\n",
    "        return np.interp(R, R_bin_centers, wp_values)\n",
    "\n",
    "    # getting \\bar{w_p}, per-bin\n",
    "    def wp_integrand(R):\n",
    "        return R * get_wp(R)\n",
    "\n",
    "    def get_bar_wp(Rmin, Rmax):\n",
    "        wp_integral = scipy.integrate.romberg(wp_integrand, a=Rmin, b=Rmax, rtol=1.48e-8, divmax=15) # integrate over R\n",
    "        return (2 / (Rmax**2 - Rmin**2)) * wp_integral\n",
    "    \n",
    "    # for last ingetral\n",
    "    def K_integrand(K, Rmin, Rmax, pimax, b_gal, PS_min = 10**-4, PS_max = 100):\n",
    "        kz_integral = get_kz_integral_spl(K, pimax, b_gal)\n",
    "        return K * get_fancyJ(Rmin, Rmax, K) * kz_integral\n",
    "    \n",
    "    def get_model_est(Rmin, Rmax, pimax, b_gal, tau=1, PS_min = 10**-4, PS_max = 100):\n",
    "        bar_wp = get_bar_wp(Rmin, Rmax)\n",
    "        K_integral = scipy.integrate.romberg(K_integrand, a=PS_min, b=PS_max, args=[Rmin, Rmax, pimax, b_gal], rtol=1.48e-8, divmax=15) # integrate over K\n",
    "        \n",
    "        return -tau * K_integral / (2*pimax + bar_wp)\n",
    "    \n",
    "    # computing the model prediction in each bin of projected separation\n",
    "    model_estimates = []\n",
    "    r_bin_centers = []\n",
    "    for rt in rel_e_measurement:\n",
    "        try:\n",
    "            model_est = get_model_est(rt['R_bin_min'], rt['R_bin_max'], rt['pimax'], b_gal=b_gal, tau=1)\n",
    "        except ValueError:\n",
    "            print('no values found for pimax = ', rt['pimax'])\n",
    "            break\n",
    "        model_estimates.append(model_est)\n",
    "        r_bin_centers.append((rt['R_bin_min']+rt['R_bin_max'])/2)\n",
    "    model_estimates = np.asarray(model_estimates)\n",
    "    r_bin_centers = np.asarray(r_bin_centers)\n",
    "    \n",
    "    return r_bin_centers, model_estimates*D_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calum_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
